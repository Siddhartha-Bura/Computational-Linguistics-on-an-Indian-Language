{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "import codecs\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    dot_product = np.dot(a, b)  # dot product\n",
    "    norm_a = np.linalg.norm(a)  # norm\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"Q1output\"+os.sep + \"100\"):\n",
    "    os.makedirs(\"Q1output\"+os.sep + \"100\")\n",
    "if not os.path.exists(\"Q1output\"+os.sep + \"50\"):\n",
    "    os.makedirs(\"Q1output\"+os.sep + \"50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_similarities(model,dimension,model_name,direct = False):\n",
    "\n",
    "    df = pd.read_csv('Word similarity'+os.sep+'hindi.txt', sep=',', header=None) # read \n",
    "    df.columns = [\"first_word\", \"second_word\",\"similarity\"]\n",
    "    ans_list = []    # consine similarities for the pairs along with true label\n",
    "    word_1 = []\n",
    "    word_2 = []\n",
    "    gts = []\n",
    "    ss = []\n",
    "    for index, row in df.iterrows():\n",
    "        pair = [row['first_word'],row['second_word']]       # Extracting pair out of file \n",
    "        word_1.append(row['first_word'])\n",
    "        word_2.append(row['second_word'])\n",
    "        gts.append(row['similarity'])\n",
    "        if(direct):\n",
    "            ans_list.append([cosine_similarity(model[pair[0]] , model[pair[1]])*10,row['similarity']])\n",
    "            ss.append(cosine_similarity(model[pair[0]] , model[pair[1]])*10)\n",
    "        else:\n",
    "            ans_list.append([cosine_similarity(model.wv[pair[0]] , model.wv[pair[1]])*10,row['similarity']])\n",
    "            ss.append(cosine_similarity(model.wv[pair[0]] , model.wv[pair[1]])*10)\n",
    "    accuracies_list = []    # threshold corresponding accuracies\n",
    "    \n",
    "    for i in [4, 5, 6, 7, 8]:\n",
    "        count = 0\n",
    "        label = []\n",
    "        for j in ans_list:\n",
    "            if ((j[0] >= i and j[1] >= i) or (j[0] < i and j[1] < i)):\n",
    "                count += 1\n",
    "            if(j[0] >=i and j[1]>=i):\n",
    "                label.append(1)\n",
    "            else:\n",
    "                label.append(0)\n",
    "        dfo = pd.DataFrame({'Word1':word_1,'Word2':word_2,'Similarity Score':ss,'Ground Truth similarity score':gts,'Label':label})\n",
    "        accuracies_list.append(count / len(ans_list))\n",
    "        dfo.loc[len(dfo.index)] = ['', '', '','',count / len(ans_list)]\n",
    "        dfo.to_csv(os.path.join('Q1output'+os.sep+str(dimension),'Q1_'+ model_name + '_similarity_'+ str(i) +'.csv'))\n",
    "    return accuracies_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_50 = 'hi'+os.sep+'50'+os.sep\n",
    "path_100 = 'hi'+os.sep+'100'+os.sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load(path_100 +'cbow' + os.sep + \"hi-d100-m2-cbow.model\") # cbow model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(model.wv.index_to_key) # list of all words in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6153846153846154,\n",
       " 0.49230769230769234,\n",
       " 0.4461538461538462,\n",
       " 0.5230769230769231,\n",
       " 0.8307692307692308]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_similarities(model,100,'cbow',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load(path_50 +'cbow' + os.sep + \"hi-d50-m2-cbow.model\") # cbow model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7076923076923077,\n",
       " 0.5692307692307692,\n",
       " 0.5076923076923077,\n",
       " 0.5538461538461539,\n",
       " 0.7846153846153846]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_similarities(model,50,'cbow',False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skipgram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load(path_100 +'sg' + os.sep +\"hi-d100-m2-sg.model\") # skipgram model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8923076923076924,\n",
       " 0.6153846153846154,\n",
       " 0.5076923076923077,\n",
       " 0.5384615384615384,\n",
       " 0.8153846153846154]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_similarities(model,100,'skipgram',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load(path_50 +'sg' + os.sep +\"hi-d50-m2-sg.model\") # skipgram model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9076923076923077,\n",
       " 0.8307692307692308,\n",
       " 0.6461538461538462,\n",
       " 0.5384615384615384,\n",
       " 0.7692307692307693]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_similarities(model,50,'skipgram',False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fasttext vectors load\n",
    "ft_vectors = np.load(path_100 +'fasttext' + os.sep  + 'hi-d100-m2-fasttext.model.wv.vectors.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = {} # dictionary of vocabulary to fasttext word vectors\n",
    "for i in range(len(words)):\n",
    "    ft_model[words[i]] = ft_vectors[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8923076923076924,\n",
       " 0.6615384615384615,\n",
       " 0.47692307692307695,\n",
       " 0.5384615384615384,\n",
       " 0.8]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_similarities(ft_model,100,'FastText',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fasttext vectors load\n",
    "ft_vectors = np.load(path_50 +'fasttext' + os.sep  + 'hi-d50-m2-fasttext.model.wv.vectors.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = {} # dictionary of vocabulary to fasttext word vectors\n",
    "for i in range(len(words)):\n",
    "    ft_model[words[i]] = ft_vectors[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8307692307692308,\n",
       " 0.8307692307692308,\n",
       " 0.5692307692307692,\n",
       " 0.5538461538461539,\n",
       " 0.7846153846153846]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_similarities(ft_model,50,'FastText',True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove model load\n",
    "glove_file = datapath(os.getcwd()+ os.sep + path_100 +'glove' + os.sep + 'hi-d100-glove.txt')\n",
    "glove_vectors = gensim.models.KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True,encoding='utf8',unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8,\n",
       " 0.6307692307692307,\n",
       " 0.47692307692307695,\n",
       " 0.5538461538461539,\n",
       " 0.8307692307692308]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_similarities(glove_vectors,100,'glove',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove model load\n",
    "glove_file = datapath(os.getcwd()+ os.sep + path_50 +'glove' + os.sep+'hi-d50-glove.txt')\n",
    "glove_vectors = gensim.models.KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True,encoding='utf8',unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8461538461538461,\n",
       " 0.7230769230769231,\n",
       " 0.6153846153846154,\n",
       " 0.5846153846153846,\n",
       " 0.8153846153846154]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_similarities(glove_vectors,50,'glove',True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j-sgUbzBXPZK",
    "outputId": "a65f201b-cf71-47e5-baa6-3b44a121005c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
      "Requirement already satisfied: seqeval[gpu] in /usr/local/lib/python3.7/dist-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval[gpu]) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers seqeval[gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-SNxLaYHU7l",
    "outputId": "6be14862-50c4-481c-d6ef-e7e3455fe95d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEnlUbgm8z3B"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sm1krxJtKxpx",
    "outputId": "6214709d-8803-4ecd-9ded-acca6c92f166"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHbqkAzFZ36V"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MjTe9tAfaIDU",
    "outputId": "2244a7b7-e583-45ac-cea0-f960bc333708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RE3VDJ3Aav9i"
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "with open('/content/drive/MyDrive/data/hindi_ner/hi_train.conll', 'r', encoding='utf-8') as in_fp:\n",
    "    local = []\n",
    "    for line in in_fp.readlines():\n",
    "        sent = line.rstrip('\\n')\n",
    "        if(len(sent) == 0):\n",
    "            sentences.append(local)\n",
    "            local = []\n",
    "        else:\n",
    "            local.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "adqJuBFi7ZXA"
   },
   "outputs": [],
   "source": [
    "global_sentence = []\n",
    "global_labels = []\n",
    "for i in sentences:\n",
    "    sentence = ''\n",
    "    tags = ''\n",
    "    for j in range(1,len(i)):\n",
    "        arr = i[j].split('_ _ ')\n",
    "        sentence += (arr[0] + ' ')\n",
    "        tags += (arr[1] + ',')\n",
    "    global_sentence.append(sentence)\n",
    "    global_labels.append(tags[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "jRy47v3D-URN",
    "outputId": "cb54af91-059a-4464-a492-68f2981b6ffd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-63d0573d-1a82-4e42-b319-f45b5232e719\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>जियोर्जियोन  ०१९।  जेपीजी  |  जियोर्जियोन  आंध...</td>\n",
       "      <td>O,O,O,O,O,B-CW,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>इस  क्षेत्र  का  सबसे  प्रसिद्ध  व्यंजन  बिरिय...</td>\n",
       "      <td>O,O,O,O,O,O,B-PROD,O,O,O,O,O,O,O,O,O,O,O,O,O,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>राजनीतिक  टिप्पणीकार  एंड्रयू  सुलिवन  ने  मान...</td>\n",
       "      <td>O,O,B-PER,I-PER,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>लाइटिंग  सर्किट  से  उपकरणों  को  जोड़ने  के  ...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-PROD,I-PROD,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>तब  से  उन्हें  तीन  बार  स्थानांतरित  किया  ग...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-LOC,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15295</th>\n",
       "      <td>चाओ  फ्रया  नदी  मेक्सिको</td>\n",
       "      <td>B-LOC,I-LOC,I-LOC,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15296</th>\n",
       "      <td>चाय  बोर्ड,  भारत  संगठन</td>\n",
       "      <td>B-GRP,I-GRP,I-GRP,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15297</th>\n",
       "      <td>कंप्यूटर  अंकुरण</td>\n",
       "      <td>O,B-PROD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15298</th>\n",
       "      <td>एयर  इंडिया  रीजनल  .  की  समीक्षाएं</td>\n",
       "      <td>B-CORP,I-CORP,I-CORP,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15299</th>\n",
       "      <td>क्वालकॉम  स्नैपड्रैगन  .  के  उदाहरण</td>\n",
       "      <td>B-PROD,I-PROD,O,O,O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15300 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63d0573d-1a82-4e42-b319-f45b5232e719')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-63d0573d-1a82-4e42-b319-f45b5232e719 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-63d0573d-1a82-4e42-b319-f45b5232e719');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "0      जियोर्जियोन  ०१९।  जेपीजी  |  जियोर्जियोन  आंध...   \n",
       "1      इस  क्षेत्र  का  सबसे  प्रसिद्ध  व्यंजन  बिरिय...   \n",
       "2      राजनीतिक  टिप्पणीकार  एंड्रयू  सुलिवन  ने  मान...   \n",
       "3      लाइटिंग  सर्किट  से  उपकरणों  को  जोड़ने  के  ...   \n",
       "4      तब  से  उन्हें  तीन  बार  स्थानांतरित  किया  ग...   \n",
       "...                                                  ...   \n",
       "15295                        चाओ  फ्रया  नदी  मेक्सिको     \n",
       "15296                         चाय  बोर्ड,  भारत  संगठन     \n",
       "15297                                 कंप्यूटर  अंकुरण     \n",
       "15298             एयर  इंडिया  रीजनल  .  की  समीक्षाएं     \n",
       "15299             क्वालकॉम  स्नैपड्रैगन  .  के  उदाहरण     \n",
       "\n",
       "                                                   label  \n",
       "0                               O,O,O,O,O,B-CW,O,O,O,O,O  \n",
       "1      O,O,O,O,O,O,B-PROD,O,O,O,O,O,O,O,O,O,O,O,O,O,O...  \n",
       "2                O,O,B-PER,I-PER,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "3      O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-PROD,I-PROD,O,...  \n",
       "4              O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-LOC,O,O,O  \n",
       "...                                                  ...  \n",
       "15295                                B-LOC,I-LOC,I-LOC,O  \n",
       "15296                                B-GRP,I-GRP,I-GRP,O  \n",
       "15297                                           O,B-PROD  \n",
       "15298                         B-CORP,I-CORP,I-CORP,O,O,O  \n",
       "15299                                B-PROD,I-PROD,O,O,O  \n",
       "\n",
       "[15300 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"sentence\":global_sentence,\"label\":global_labels})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VwxYeGBWLvzJ"
   },
   "outputs": [],
   "source": [
    "tags_list = []\n",
    "for index, item in enumerate(global_labels):\n",
    "    tags_list.extend(global_labels[index].split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y30mmXNNM71L"
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zlKUU9kI86q"
   },
   "outputs": [],
   "source": [
    "unique_list = list(Counter(tags_list).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrsJ1A-RNiOR"
   },
   "outputs": [],
   "source": [
    "if '' in unique_list:\n",
    "  unique_list.remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yjXENZxfNKU5",
    "outputId": "89de70f2-4ba6-4c39-f3eb-8d55a8e43cad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-CW',\n",
       " 'B-PROD',\n",
       " 'B-PER',\n",
       " 'I-PER',\n",
       " 'I-PROD',\n",
       " 'B-LOC',\n",
       " 'B-CORP',\n",
       " 'I-CORP',\n",
       " 'B-GRP',\n",
       " 'I-GRP',\n",
       " 'I-CW',\n",
       " 'I-LOC']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CFRDM8WsQXvL",
    "outputId": "119e0781-a74c-42cc-ca68-a5edd6a2f855"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-CW',\n",
       " 2: 'B-PROD',\n",
       " 3: 'B-PER',\n",
       " 4: 'I-PER',\n",
       " 5: 'I-PROD',\n",
       " 6: 'B-LOC',\n",
       " 7: 'B-CORP',\n",
       " 8: 'I-CORP',\n",
       " 9: 'B-GRP',\n",
       " 10: 'I-GRP',\n",
       " 11: 'I-CW',\n",
       " 12: 'I-LOC'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_ids = {k: v for v, k in enumerate(unique_list)}\n",
    "ids_to_labels = {v: k for v, k in enumerate(unique_list)}\n",
    "ids_to_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "awmBQuUkRHcf",
    "outputId": "10ec7740-a4f5-4306-d4fc-b55f95f21e2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-CORP': 7,\n",
       " 'B-CW': 1,\n",
       " 'B-GRP': 9,\n",
       " 'B-LOC': 6,\n",
       " 'B-PER': 3,\n",
       " 'B-PROD': 2,\n",
       " 'I-CORP': 8,\n",
       " 'I-CW': 11,\n",
       " 'I-GRP': 10,\n",
       " 'I-LOC': 12,\n",
       " 'I-PER': 4,\n",
       " 'I-PROD': 5,\n",
       " 'O': 0}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9NHphIq-JYf5",
    "outputId": "95e073d8-e6f8-4843-9fc1-aebba5b38b70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15300, 2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qug55kETElx"
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "with open('/content/drive/MyDrive/data/hindi_ner/hi_dev.conll', 'r', encoding='utf-8') as in_fp:\n",
    "    local = []\n",
    "    for line in in_fp.readlines():\n",
    "        sent = line.rstrip('\\n')\n",
    "        if(len(sent) == 0):\n",
    "            sentences.append(local)\n",
    "            local = []\n",
    "        else:\n",
    "            local.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ReBGiwpOTRiU"
   },
   "outputs": [],
   "source": [
    "global_sentence = []\n",
    "global_labels = []\n",
    "for i in sentences:\n",
    "    sentence = ''\n",
    "    tags = ''\n",
    "    for j in range(1,len(i)):\n",
    "        arr = i[j].split('_ _ ')\n",
    "        sentence += (arr[0] + ' ')\n",
    "        tags += (arr[1] + ',')\n",
    "    global_sentence.append(sentence)\n",
    "    global_labels.append(tags[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "C2YnRqnRTYMB",
    "outputId": "1059428b-1475-403d-bad8-6a279e178246"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4b7614a4-0f3a-4a93-89cc-07bc1b740d80\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>१४९२  में  एक  चार्टर  के  आधार  पर,  उसके  पि...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,B-LOC,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>इस  विश्वविद्यालय  को  ओडिशा  के  नॉलेज  हब  म...</td>\n",
       "      <td>O,O,O,B-LOC,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>इस  तरह  का  पहला  बेड़ा,  आर12  ,  १९४८  में ...</td>\n",
       "      <td>O,O,O,O,O,B-PROD,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>इस  बिंदु  पर,  वायरल  संजीन  को  अज्ञात  तंत्...</td>\n",
       "      <td>O,O,O,O,B-PROD,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ग्वाटेमाला  में,  कमजोर  तूफान  ने  अत्यधिक  व...</td>\n",
       "      <td>B-LOC,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>यह  नए  वाहनों,  इस्तेमाल  किए  गए  वाहनों  और...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-CORP,I-CORP,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>यह  अपने  प्रवक्ता  के  रूप  में  व्हूपी  गोल्...</td>\n",
       "      <td>O,O,O,O,O,O,B-PER,I-PER,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>कभी-कभी  नारियल  के  दूध  की  मिठास  के  आधार ...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,B-PROD,I-PROD,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>बपतिस्मात्मक  फ़ॉन्ट  ,  जिसमें  करूबों  से  त...</td>\n",
       "      <td>B-PROD,I-PROD,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>अधिकांश  सधन  चक  रिकॉर्डिंग  में  दो  डिस्क  ...</td>\n",
       "      <td>O,B-PROD,I-PROD,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b7614a4-0f3a-4a93-89cc-07bc1b740d80')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-4b7614a4-0f3a-4a93-89cc-07bc1b740d80 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-4b7614a4-0f3a-4a93-89cc-07bc1b740d80');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              sentence  \\\n",
       "0    १४९२  में  एक  चार्टर  के  आधार  पर,  उसके  पि...   \n",
       "1    इस  विश्वविद्यालय  को  ओडिशा  के  नॉलेज  हब  म...   \n",
       "2    इस  तरह  का  पहला  बेड़ा,  आर12  ,  १९४८  में ...   \n",
       "3    इस  बिंदु  पर,  वायरल  संजीन  को  अज्ञात  तंत्...   \n",
       "4    ग्वाटेमाला  में,  कमजोर  तूफान  ने  अत्यधिक  व...   \n",
       "..                                                 ...   \n",
       "795  यह  नए  वाहनों,  इस्तेमाल  किए  गए  वाहनों  और...   \n",
       "796  यह  अपने  प्रवक्ता  के  रूप  में  व्हूपी  गोल्...   \n",
       "797  कभी-कभी  नारियल  के  दूध  की  मिठास  के  आधार ...   \n",
       "798  बपतिस्मात्मक  फ़ॉन्ट  ,  जिसमें  करूबों  से  त...   \n",
       "799  अधिकांश  सधन  चक  रिकॉर्डिंग  में  दो  डिस्क  ...   \n",
       "\n",
       "                                                 label  \n",
       "0            O,O,O,O,O,O,O,O,O,O,O,B-LOC,O,O,O,O,O,O,O  \n",
       "1                        O,O,O,B-LOC,O,O,O,O,O,O,O,O,O  \n",
       "2                     O,O,O,O,O,B-PROD,O,O,O,O,O,O,O,O  \n",
       "3    O,O,O,O,B-PROD,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O...  \n",
       "4                          B-LOC,O,O,O,O,O,O,O,O,O,O,O  \n",
       "..                                                 ...  \n",
       "795  O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-CORP,I-CORP,O,O,...  \n",
       "796                  O,O,O,O,O,O,B-PER,I-PER,O,O,O,O,O  \n",
       "797    O,O,O,O,O,O,O,O,O,O,O,B-PROD,I-PROD,O,O,O,O,O,O  \n",
       "798  B-PROD,I-PROD,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "799                O,B-PROD,I-PROD,O,O,O,O,O,O,O,O,O,O  \n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame({\"sentence\":global_sentence,\"label\":global_labels})\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lgNSM8Xz79Mg"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 2\n",
    "LEARNING_RATE = 3*1e-03\n",
    "MAX_GRAD_NORM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V7NijqaFupw0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eh3ckSO0YMZW"
   },
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "  def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        sentence = self.data.sentence[index].strip()\n",
    "        word_labels = self.data.label[index].split(\",\") \n",
    "\n",
    "        encoding = self.tokenizer(sentence,\n",
    "                             return_offsets_mapping=True, \n",
    "                             padding='max_length', \n",
    "                             truncation=True, \n",
    "                             max_length=self.max_len)\n",
    "        \n",
    "        labels = [labels_to_ids[label] for label in word_labels]\n",
    "\n",
    "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.as_tensor(labels[0])\n",
    "        \n",
    "        return item\n",
    "\n",
    "  def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrkdZBLYHVcB",
    "outputId": "01a62481-c6fe-4099-b840-f61497874128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (15300, 2)\n",
      "TRAIN Dataset: (13005, 2)\n",
      "VALIDATION Dataset: (2295, 2)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.85\n",
    "\n",
    "train_dataset = df.sample(frac=train_size,random_state=200)\n",
    "valid_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "\n",
    "print(\"VALIDATION Dataset: {}\".format(valid_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "\n",
    "valid_set = dataset(valid_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5F3Fk1qTqnG"
   },
   "outputs": [],
   "source": [
    "test_df = test_df.reset_index(drop=True)\n",
    "testing_set = dataset(test_df,tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "phmPylgAm8Xy",
    "outputId": "2af41a9c-8b68-48cc-fcef-40fd9fb6c402"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'input_ids': tensor([    2,   114,  3642, 12917,   507, 23316,   367, 29631,  4384,   293,\n",
       "         57631,  9327,   229, 32721,  1883, 79942, 42601,   507,  5650, 17636,\n",
       "            15,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'labels': tensor(0),\n",
       " 'offset_mapping': tensor([[ 0,  0],\n",
       "         [ 0,  2],\n",
       "         [ 3,  6],\n",
       "         [ 7,  9],\n",
       "         [10, 11],\n",
       "         [12, 16],\n",
       "         [16, 17],\n",
       "         [18, 22],\n",
       "         [23, 25],\n",
       "         [27, 28],\n",
       "         [29, 33],\n",
       "         [34, 37],\n",
       "         [38, 39],\n",
       "         [40, 44],\n",
       "         [45, 47],\n",
       "         [49, 53],\n",
       "         [54, 58],\n",
       "         [59, 60],\n",
       "         [61, 63],\n",
       "         [65, 67],\n",
       "         [68, 69],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0]]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIw793myWOmi"
   },
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)\n",
    "valid_loader = DataLoader(valid_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8KAea7Qqt6GU",
    "outputId": "99ebff7d-a5c8-49ba-e879-169527b00c97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fEIYC0FhXw9X"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7bKz0mNQXcAR"
   },
   "outputs": [],
   "source": [
    "\n",
    "class additional_nn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(additional_nn, self).__init__()\n",
    "\n",
    "        self.auto = AutoModel.from_pretrained('ai4bharat/indic-bert')\n",
    "        self.classifier =  nn.Sequential(nn.Linear(768, 384), nn.ReLU(),\n",
    "                                         nn.Linear(384, 192),nn.ReLU(),nn.Dropout(0.20),\n",
    "                                         nn.Linear(192, 96),nn.ReLU(),nn.Dropout(0.20),\n",
    "                                         nn.Linear(96,48),nn.ReLU(),nn.Dropout(0.10),\n",
    "                                         nn.Linear(48,24),nn.ReLU(),nn.Dropout(0.05),\n",
    "                                         nn.Linear(24,13))\n",
    "        \n",
    "    def forward(self,ids,attention_mask):\n",
    "      output = self.auto(input_ids=ids,attention_mask=attention_mask)\n",
    "      hidden_stat = output[0][:, 0, :]\n",
    "      logits = self.classifier(hidden_stat)\n",
    "      return logits\n",
    "\n",
    "    def trigger_no_bert(self):\n",
    "        for p in self.auto.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def feed_to_device(self,device):\n",
    "        self.auto.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbNHDmq4iRfJ"
   },
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lx682Qaq7hC"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YEtgRHxDiuAy",
    "outputId": "d3d9043e-b408-4a21-ca53-e3cc451c4988"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertModel: ['predictions.decoder.weight', 'sop_classifier.classifier.bias', 'sop_classifier.classifier.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.weight', 'predictions.dense.bias', 'predictions.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "new_model = additional_nn()\n",
    "new_model.trigger_no_bert()\n",
    "new_model.feed_to_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zWWKTMSTi2NC",
    "outputId": "4c604922-529f-44bd-b040-aceaf9d92861"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "additional_nn(\n",
       "  (auto): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(200000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                (output_dropout): Dropout(p=0, inplace=False)\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (pooler_activation): Tanh()\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=384, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=384, out_features=192, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.2, inplace=False)\n",
       "    (5): Linear(in_features=192, out_features=96, bias=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=96, out_features=48, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Dropout(p=0.1, inplace=False)\n",
       "    (11): Linear(in_features=48, out_features=24, bias=True)\n",
       "    (12): ReLU()\n",
       "    (13): Dropout(p=0.05, inplace=False)\n",
       "    (14): Linear(in_features=24, out_features=13, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLFivpkwW1HY"
   },
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "\n",
    "  tr_loss, tr_accuracy = 0, 0\n",
    "  nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  tr_preds, tr_labels = [], []\n",
    "  \n",
    "  optimizer = torch.optim.Adam(params=new_model.parameters(), lr=LEARNING_RATE)\n",
    "  new_model.train()\n",
    "  for idx, batch in enumerate(training_loader):\n",
    "    ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "    mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "    labels = batch['labels'].to(device, dtype = torch.long)\n",
    "    \n",
    "    logits = new_model(ids,mask)\n",
    "    loss = loss_function(logits, labels)\n",
    "    tr_loss += loss.item()\n",
    "  \n",
    "    nb_tr_steps += 1\n",
    "    nb_tr_examples += labels.size(0)\n",
    "    \n",
    "    if idx % 100==0:\n",
    "        loss_step = tr_loss/nb_tr_steps\n",
    "        print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "\n",
    "    flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "    active_logits = logits.view(-1,13) # shape (batch_size * seq_len, num_labels)\n",
    "    flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len)\n",
    "\n",
    "    active_accuracy = labels.view(-1) != -100\n",
    "\n",
    "    labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "    predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "    tr_labels.extend(labels)\n",
    "    tr_preds.extend(predictions)\n",
    "\n",
    "    tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "    tr_accuracy += tmp_tr_accuracy\n",
    "  \n",
    "    torch.nn.utils.clip_grad_norm_(\n",
    "        parameters=new_model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "    )\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  epoch_loss = tr_loss / nb_tr_steps\n",
    "  tr_accuracy= tr_accuracy / nb_tr_steps\n",
    "  print(f\"Training loss epoch: {epoch_loss}\")\n",
    "  print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y07Ybw8rZeZ7",
    "outputId": "b6754ae2-9b44-40d2-95a0-5e5e2bccc42f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Training loss per 100 training steps: 2.593238115310669\n",
      "Training loss per 100 training steps: 1.0096768950398016\n",
      "Training loss per 100 training steps: 0.9471709672454282\n",
      "Training loss per 100 training steps: 0.9368551983761035\n",
      "Training loss per 100 training steps: 0.8926938281596599\n",
      "Training loss per 100 training steps: 0.8779587533488542\n",
      "Training loss per 100 training steps: 0.8674344247402298\n",
      "Training loss per 100 training steps: 0.8546844210008029\n",
      "Training loss per 100 training steps: 0.8496953718313079\n",
      "Training loss per 100 training steps: 0.8496262861289638\n",
      "Training loss per 100 training steps: 0.8495418255112239\n",
      "Training loss per 100 training steps: 0.8396045398068607\n",
      "Training loss per 100 training steps: 0.8385532449924703\n",
      "Training loss per 100 training steps: 0.8328988993816725\n",
      "Training loss per 100 training steps: 0.8261947624138067\n",
      "Training loss per 100 training steps: 0.8228587359003847\n",
      "Training loss per 100 training steps: 0.8192421814123125\n",
      "Training loss epoch: 0.8188835660403486\n",
      "Training accuracy epoch: 0.8119157441574415\n",
      "Training epoch: 2\n",
      "Training loss per 100 training steps: 0.6026530861854553\n",
      "Training loss per 100 training steps: 0.7106554042732361\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RIVVfFHi7Aw7"
   },
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            \n",
    "            ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "            labels = batch['labels'].to(device, dtype = torch.long)\n",
    "            \n",
    "            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += labels.size(0)\n",
    "        \n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "              \n",
    "\n",
    "            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            \n",
    "            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        \n",
    "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "            eval_labels.extend(labels)\n",
    "            eval_preds.extend(predictions)\n",
    "            \n",
    "            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    labels = [ids_to_labels[id.item()] for id in eval_labels]\n",
    "    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BrxRjvxApY8"
   },
   "outputs": [],
   "source": [
    "labels, predictions = valid(new_model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0jDNXrjr-6BW"
   },
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "print(classification_report(labels, predictions))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Q@2_mine.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
